---
title: "Exam 1 BMI 6106"
output:
  html_document:
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: no
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: '2'
  word_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Due March 25th 11:59pm

### As for other problem sets for this course, all answers should be submitted as a single .R file. To receive full credit for answers, make sure to (1) annotate your code, (2) use annotations to explain your reasoning, and (3) ensure that your code can be run. 

#### In this assignment we are going to review the concepts from class this week. However, concepts build on each other for every test you run you need to make sure that the data meets the appropiate criteria to be able to run the test ####Important: Use comments throughout your code to:

#### Indicate which question you are answering

#### Example: #Question 1A, #Question 1B, etc

#### Annotate your work

#### Examples: #Calculate the mean for ‘height’

#### P(being on time) = 1/6

#### If you do not provide annotation, we will not be able to give you full credit for solving the problems.

#### If you have any questions about what is being asked or what you need to do in order to solve the problems, please reach out to a TA or instructor as soon as possible. If it is necessary to provide additional information or corrections, updated information will be posted on the HW3 Assignment page in Canvas.


## Q1. 5 points 

### Which of the following statements about multicollinearity in regression analysis is true?

#### a. Multicollinearity occurs when the correlation between two independent variables is close to 0.

#### b. Multicollinearity can lead to unstable coefficient estimates and inflated standard errors.

#### c. Multicollinearity affects only the interpretation of the intercept term.

#### d. Multicollinearity is more problematic in simple linear regression than in multiple regression.
```{r Q1}
# b. Multicollinearity can lead to unstable coefficient estimates and inflated standard errors.

```
## Q2. 5 points 

### Suppose you are building a regression model to predict housing prices. Which type of variable is “neighborhood”?

#### a. Continuous

#### b. Ordinal

#### c. Nominal

#### d. Interval

#### e. Mixed
```{r Q2}
# c. Nominal

```
## Q3. 5 points 

### In a logistic regression model, what does the odds ratio represent?

#### a. The change in the dependent variable for a one-unit change in the independent variable.

#### b. The probability of the dependent variable being 1.

#### c. The ratio of the odds of success to the odds of failure.

#### d. The coefficient of determination (R-squared).

#### e. The absolute probability derived from the least squares function
```{r Q3}
# c. The ratio of the odds of success to the odds of failure.

```
## Q4. 15 points

### Using the bayes theorem we can derive the (maybe surprising) result that in families that have 2 children along with the knowledge that at least one of the children is a boy born on a Wednesday, the probability that the family has 2 boys is 13/27 (~.48). We can test this calculation by randomly generating many “two child families” and counting the number that fulfill the criteria of (1) having a boy born on a Wednesday and (2) of these families having two boys. 

###  Write R code to simulate 10,000 two-child families and count the frequency of two-boy families amongst all families with at least one Wednesday-born boy. In your answer, you should (A, 8 pts) provide the annotated code and report the frequency your code produced; (B, 4 pts) explain your approach. The code should be annotated and runnable by us if we copy into RStudio. As before, assume that children are born with exactly 50/50 probability that they are a “boy” or a “girl” and that births occur on each day of the week with an equal probability. 




```{r Q4}
#(there are many ways to approach this question). You can create a function that simulates the families or just sample the families n number of times

# Part A:
# set seed for reproducibility
set.seed(1)

# Initialize variables
n_simulations <- 10000
two_boy <- 0
one_wednesday_boy <- 0

# Define possible outcomes for gender and days of the week
genders <- c("Boy", "Girl")
days_of_week <- c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")

# Simulate 10,000 families
for (i in 1:n_simulations) {
  # Simulate genders for two children
  child_genders <- sample(genders, size = 2, replace = TRUE, prob = c(0.5, 0.5))
  
  # Simulate birth days for two children
  birth_days <- sample(days_of_week, size = 2, replace = TRUE)
  
  # Check if at least one boy was born on a Wednesday
  if ("Wednesday" %in% birth_days[child_genders == "Boy"]) {
    one_wednesday_boy <- one_wednesday_boy + 1
    
    # If there is at least one Wednesday boy, check if both are boys
    if (all(child_genders == "Boy")) {
      two_boy <- two_boy + 1
    }
  }
}
# calculate frequency of two-boy families among those that have at least one boy on Wednesday
frequency <- two_boy / one_wednesday_boy
cat("Frequency: ", frequency )

# Part B:
# In this approach, I generated 2 child genders with 50/50 probability and a birth day with equal probabilities. Then I checked if one of the children was a boy born on a Wednesday, and if true, I added +1 to the one_wednesday_boy count. Then if there was one boy born on Wednesday I checked if both children were boys and if true I added +1 to the two_boy count. I ran this simulation 10000 times and calculated the frequency of two-boy families among those that have at least one boy on Wednesday. The resulting frequency was 0.48, which is what we expected to see.
```

## Q5. 20 points

### Using the attached set of “datasaurus12” datasets 

#### A. produce a table with the following parameters for each dataset (x-mean, y-mean, x-standard deviation, y-standard deviation, Pearson correlation) (5 points)
#### B. Produce a scatteplot for each one of these datasets (ideally in a facetted plot e.g. facet_grap function from ggplot) (5 points)
#### C. Why are these statitical paramenter not sufficient to distinguish any of the datasets from each other. (5 points)
#### D. Identify and use another summary statistic in R that can discriminate between all the datasaurus12 datasets to at least 1 decimal place. You may use any available R package to run your analysis. In your answer, you should provide the name of the function you use, identify the library in which it can be found (if it is not a core R function), and provide a table of the values you obtain from the datasaurus12 datasets. (5 points)



```{r Q5}
library(readr)
library(dplyr)
library(purrr)

# List all CSV files in the folder
csv_files <- list.files(path = "datasaurus12", pattern = "\\.csv$", full.names = TRUE)

# Create a named list where each name is the file name without the extension
names_list <- tools::file_path_sans_ext(basename(csv_files))

# Read each CSV file into its own data frame within a named list
data_frames_list <- setNames(lapply(csv_files, function(file) read_csv(file, show_col_types = FALSE)), names_list)

# Part A:
# Function to calculate summary statistics for each data frame
calculate_summary <- function(df) {
  summary <- df %>%
    summarize(
      x_mean = mean(x, na.rm = TRUE),
      y_mean = mean(y, na.rm = TRUE),
      x_sd = sd(x, na.rm = TRUE),
      y_sd = sd(y, na.rm = TRUE),
      pearson_correlation = cor(x, y, use = "complete.obs")
    )
  return(summary)
}

# Apply the function to each data frame in the list and combine the results
summary_table <- map_df(data_frames_list, calculate_summary, .id = "Dataset")

# Print the summary table
print(summary_table)

# Part B:
# Combine data into single dataset with id as Dataset name
combined_data <- bind_rows(data_frames_list, .id = "dataset")

# Plot each dataset in facetted plot
ggplot(combined_data, aes(x = x, y = y)) +
  geom_point() +
  facet_wrap(~ dataset, scales = "free") +
  theme_minimal() +
  labs(title = "Datasets Scatterplots", x = "X", y = "Y")

```

------------------------------------------------------------------------

## Q6. 10 points

### The file anscombe.txt contains 4 different datasets constructed by Anscombe in 1973. The x and y variables are matched to each dataset (e.g., for dataset 1, x1 corresponds to y1).


```{r Q6}

# This is the dataset:
# case x1 x2 x3 x4    y1   y2    y3    y4
# 1    10 10 10  8  8.04 9.14  7.46  6.58
# 2     8  8  8  8  6.95 8.14  6.77  5.76
# 3    13 13 13  8  7.58 8.74 12.74  7.71
# 4     9  9  9  8  8.81 8.77  7.11  8.84
# 5    11 11 11  8  8.33 9.26  7.81  8.47
# 6    14 14 14  8  9.96 8.10  8.84  7.04
# 7     6  6  6  8  7.24 6.13  6.08  5.25
# 8     4  4  4 19  4.26 3.10  5.39 12.50
# 9    12 12 12  8 10.84 9.13  8.15  5.56
# 10    7  7  7  8  4.82 7.26  6.42  7.91
# 11    5  5  5  8  5.68 4.74  5.73  6.89

```

### A. Use R to create a scatterplot for each dataset. In your answer, you should provide the code and clearly annotate which section of code will produce each plot. (2 points)
### B. Use R to run a simple linear regression for each dataset. In your answer, you should provide both the annotated code and the resulting linear function for each model.(2 points)
### C. Use R to generate residuals plots for each dataset. In your answer, you should provide the annotated code. (3 points)
### D. State the assumptions for linear regression. (3 points)
### E. For each model, use a few sentences to (i) describe the model, (ii) indicate if there is a problem with the model, and (iii) explain what can be done to fix it. (5 points)
```{r Q6}


```

## Q7. 10 points

### we classify 2000 email in two groups: 1000 emails as spam and 1000 emails as non-spam. 210 of the spam emails contained the phrase This isn’t spam, 99 had the word prize and 110 the word prince. Of the 99 that contained the word prize, 79 also contained the word prince. On the other hand, of the 1000 non-spam emails, only 23 had the phrase this isn’t spam, 80 the word prize and 110 the word prince. Of the 80 that contained the word prize 8 also contained the word prince.


### Assuming that the a priori probability of any message being spam is 0.5, what is the probability that an email is spam given it contains the phrase This isn't spam
```{r Q7}


```
## Q8. 15 points

### From the Cleveland Heart Disease dataset (attached to this folder - [ https://archive.ics.uci.edu/ml/datasets/Heart+Disease ] ) 

### A. if we pick 25 patients randomly, find the probability that at least 3 have less than 50 percent diameter narrowing (num variable 14 in dataset state 0 - condition). Answer this question using one of the distributions seen in class you can confirm the answer with the R functions. (7 points)

### B. Assume that patients are examined at random, what is the average number of patients before the first patient with cholesterol levels above than 300 (including 300) is encountered? Answer this question using one of the distributions seen in class you can confirm the answer with the R functions. (8 points)
```{r Q8}


```
## Q9. 15 points

### From the Cleveland Heart Disease dataset:


### A. calculate the mean and variance for the maximum heart rate achieved during the exercise test (thalach). (2 points)
### B. Generate 10000 bootstraps for this variable (sample with replacement) and calculate the mean, median, and variance for each of the bootstrap samples.Just creating the object(s) that contains these values is sufficient. (3 points)
### C. Calculate the mean, standard deviation, standard error, and 95% CI of the distribution of **means** from the bootstrap samples (one value for each parameter). (3 points)
### D. Produce a density plot of the distribution mean from the bootstraps. (3 points)
### E. In one of two sentences write an overall conclusion of applying the bootstrap to increase the precision to the estimation of this variable. (4 points)
```{r Q9}


```