color = my_colors,
main = "Heatmap of Gene Expression",
xlab = "Random Samples",
ylab = "Genes",
legend_breaks = c(-2, 2),
legend_labels = c("Downregulated", "Upregulated"))
library(factoextra)
# create filtered pca dataframe
pca_df <- data.frame(scaled)
pca_groups <- data.frame(Diagnosis = filtered$Diagnosis)
pca_groups <- as.data.frame(pca_groups[-rows_to_remove, ])
colnames(pca_groups)[1] <- "Diagnosis"
# Compute the covariance matrix
covariance_matrix <- cov(pca_df)
# Identify collinear variables
threshold <- 0.9
collinear_variables <- list()
for (i in 1:(ncol(covariance_matrix) - 1)) {
for (j in (i + 1):ncol(covariance_matrix)) {
if (abs(covariance_matrix[i, j]) > threshold) {
collinear_variables[[length(collinear_variables) + 1]] <- c(colnames(pca_df)[i], colnames(pca_df)[j])
}
}
}
# remove collinear columns
# Loop through the list of collinear variables and remove the first variable from pca_df
for (collinear_pair in collinear_variables) {
pca_df <- pca_df[, !(colnames(pca_df) %in% collinear_pair[1])]
}
# perform pca
pca_result <- prcomp(pca_df, scale. = FALSE)
# Examine the summary of PCA result to decide on the number of components
#summary(pca_result)
# Select the Number of Principal Components
cumulative_var <- cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2)
# Extract a number of principal components, for example, the first two
num_components <- 2  # Adjust based on your analysis
pc_scores <- data.frame(pca_result$x[, 1:num_components])
# Add the Diagnosis back to the principal components dataframe and convert to factor
pc_scores <- cbind(pca_groups, pc_scores)
pc_scores$Diagnosis <- as.factor(pc_scores$Diagnosis)
pc_scores <- as.data.frame(pc_scores)
# Get eigenvalues
eigenvectors <- pca_result$rotation
library("GGally")
# Extract the first 4 principal components
pca_subset <- pca_result$x[, 1:4]
# Assuming pca_subset is a matrix
pca_subset <- as.data.frame(pca_subset)
# Add diagnosis column to pca_subset
pca_subset$Diagnosis <- factor(pca_groups$Diagnosis, levels = c(0, 1), labels = c("normal", "tumor"))
# PCA1 vs PCA2
fviz_pca_ind(pca_result,
geom.ind = "point",            # Show points only
col.ind = factor(pca_subset$Diagnosis, levels = unique(pca_subset$Diagnosis)),  # Color by groups
palette = c("steelblue2", "firebrick3"),
addEllipses = TRUE,           # Concentration ellipses
legend.title = "Groups",
title = "PCA Clusters",
col.lab = c("normal" = "steelblue2", "tumor" = "firebrick3"))
# Perform logistic regression using the principal components
lg_model <- glm(Diagnosis ~ ., data = pc_scores, family = "binomial")
lg_reduced <- glm(Diagnosis ~ PC1, data = pc_scores, family = "binomial")
# compare reduced with full model
anova(lg_reduced, lg_model, test = "LRT")
# the p-value is > 0.05.
# Therefore, we fail to reject the null hypothesis, suggesting that using 1 PCA component is a better model than using all PCA components.
# Check the summary of the model
summary(lg_reduced)
# OR for PC1
exp(coef(lg_reduced)["PC1"])
# The p-value is <0.05 so we conclude that PC1 gene expression is significantly associated with the presence of tumor.
# the odds of developing a tumor from PC1 gene expression is 2.3 times that of non-expression.
par(mfrow = c(2, 2))
plot(lg_reduced)
library(pROC)
# Predict probabilities
probabilities <- predict(lg_reduced, type = "response")
# Create a prediction object
prediction <- prediction(probabilities, pc_scores$Diagnosis)
View(pc_scores)
# Subset the normal and tumor patients
normal_patients <- pc_scores["Diagnosis" == 0 ]  # first 50 are normal
View(normal_patients)
# Subset the normal and tumor patients
normal_patients <- pc_scores["Diagnosis"] == 0 # first 50 are normal
# Subset the normal and tumor patients
normal_patients <- pc_scores[pc_scores$Diagnosis == 0, ]
View(normal_patients)
tumor_patients <- pc_scores[pc_scores$Diagnosis == 1, ]
View(tumor_patients)
# Sample from normal patients with replacement to increase their count
oversampled_normals <- normal_patients[sample(nrow(normal_patients), 400, replace = TRUE), ]
View(oversampled_normals)
# Combine the oversampled normals with the tumor patients
oversampled_pc_scores <- rbind(oversampled_normals, tumor_patients)
# Perform logistic regression using the principal components
lg_model <- glm(Diagnosis ~ ., data = oversampled_pc_scores, family = "binomial")
lg_reduced <- glm(Diagnosis ~ PC1, data = oversampled_pc_scores, family = "binomial")
# compare reduced with full model
anova(lg_reduced, lg_model, test = "LRT")
# the p-value is > 0.05.
# Therefore, we fail to reject the null hypothesis, suggesting that using 1 PCA component is a better model than using all PCA components.
# Check the summary of the model
summary(lg_reduced)
# OR for PC1
exp(coef(lg_reduced)["PC1"])
# The p-value is <0.05 so we conclude that PC1 gene expression is significantly associated with the presence of tumor.
# the odds of developing a tumor from PC1 gene expression is 2.3 times that of non-expression.
par(mfrow = c(2, 2))
plot(lg_reduced)
library(pROC)
# Predict probabilities
probabilities <- predict(lg_reduced, type = "response")
# Create a prediction object
prediction <- prediction(probabilities, oversampled_pc_scores$Diagnosis)
library(pROC)
# Create a prediction object
prediction <- prediction(probabilities, oversampled_pc_scores$Diagnosis)
View(oversampled_pc_scores)
# Perform logistic regression using the principal components
lg_model <- glm(Diagnosis ~ ., data = oversampled_pc_scores, family = "binomial")
lg_reduced <- glm(Diagnosis ~ PC1, data = oversampled_pc_scores, family = "binomial")
# compare reduced with full model
anova(lg_reduced, lg_model, test = "LRT")
# the p-value is > 0.05.
# Therefore, we fail to reject the null hypothesis, suggesting that using 1 PCA component is a better model than using all PCA components.
# Check the summary of the model
summary(lg_reduced)
# OR for PC1
exp(coef(lg_reduced)["PC1"])
# The p-value is <0.05 so we conclude that PC1 gene expression is significantly associated with the presence of tumor.
# the odds of developing a tumor from PC1 gene expression is 2.3 times that of non-expression.
par(mfrow = c(2, 2))
plot(lg_reduced)
View(pca_df)
View(pca_groups)
pca_combined <- cbind(pca_groups, pca_df)
View(pca_combined)
pca_normal <- pca_combined[pca_combined$Diagnosis == 0, ]
pca_tumor <- pca_combined[pca_combined$Diagnosis == 1, ]
View(pca_normal)
# Sample from normal patients with replacement to increase their count
oversampled_normals <- pca_normal[sample(nrow(pca_normal), 400, replace = TRUE), ]
# Combine the oversampled normals with the tumor patients
pca_df <- rbind(oversampled_normals, pca_tumor)
View(pca_df)
# create filtered pca dataframe
pca_df <- data.frame(scaled)
View(pca_df)
# Combine the oversampled normals with the tumor patients
oversampled_pca <- rbind(oversampled_normals, pca_tumor)
# Separate diagnosis group with oversampled data
pca_df <- subset(oversampled_pca, select = -Diagnosis)
View(pca_df)
pca_groups <- subset(oversampled_pca, select = Diagnosis)
library(factoextra)
# Compute the covariance matrix
covariance_matrix <- cov(pca_df)
# Identify collinear variables
threshold <- 0.9
collinear_variables <- list()
for (i in 1:(ncol(covariance_matrix) - 1)) {
for (j in (i + 1):ncol(covariance_matrix)) {
if (abs(covariance_matrix[i, j]) > threshold) {
collinear_variables[[length(collinear_variables) + 1]] <- c(colnames(pca_df)[i], colnames(pca_df)[j])
}
}
}
# remove collinear columns
# Loop through the list of collinear variables and remove the first variable from pca_df
for (collinear_pair in collinear_variables) {
pca_df <- pca_df[, !(colnames(pca_df) %in% collinear_pair[1])]
}
# perform pca
pca_result <- prcomp(pca_df, scale. = FALSE)
# Examine the summary of PCA result to decide on the number of components
#summary(pca_result)
# Select the Number of Principal Components
cumulative_var <- cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2)
# Extract a number of principal components, for example, the first two
num_components <- 2  # Adjust based on your analysis
pc_scores <- data.frame(pca_result$x[, 1:num_components])
# Add the Diagnosis back to the principal components dataframe and convert to factor
pc_scores <- cbind(pca_groups, pc_scores)
pc_scores$Diagnosis <- as.factor(pc_scores$Diagnosis)
pc_scores <- as.data.frame(pc_scores)
# Get eigenvalues
eigenvectors <- pca_result$rotation
library("GGally")
# Extract the first 4 principal components
pca_subset <- pca_result$x[, 1:4]
# Assuming pca_subset is a matrix
pca_subset <- as.data.frame(pca_subset)
# Add diagnosis column to pca_subset
pca_subset$Diagnosis <- factor(pca_groups$Diagnosis, levels = c(0, 1), labels = c("normal", "tumor"))
# PCA1 vs PCA2
fviz_pca_ind(pca_result,
geom.ind = "point",            # Show points only
col.ind = factor(pca_subset$Diagnosis, levels = unique(pca_subset$Diagnosis)),  # Color by groups
palette = c("steelblue2", "firebrick3"),
addEllipses = TRUE,           # Concentration ellipses
legend.title = "Groups",
title = "PCA Clusters",
col.lab = c("normal" = "steelblue2", "tumor" = "firebrick3"))
# Perform logistic regression using the principal components
lg_model <- glm(Diagnosis ~ ., data = oversampled_pc_scores, family = "binomial")
lg_reduced <- glm(Diagnosis ~ PC1, data = oversampled_pc_scores, family = "binomial")
# compare reduced with full model
anova(lg_reduced, lg_model, test = "LRT")
# the p-value is > 0.05.
# Therefore, we fail to reject the null hypothesis, suggesting that using 1 PCA component is a better model than using all PCA components.
# Check the summary of the model
summary(lg_reduced)
# OR for PC1
exp(coef(lg_reduced)["PC1"])
# The p-value is <0.05 so we conclude that PC1 gene expression is significantly associated with the presence of tumor.
# the odds of developing a tumor from PC1 gene expression is 2.3 times that of non-expression.
par(mfrow = c(2, 2))
plot(lg_reduced)
library(pROC)
# Predict probabilities
probabilities <- predict(lg_reduced, type = "response")
# Create a ROC curve object
roc_curve <- roc(oversampled_pc_scores$Diagnosis, probabilities)
# Plot the ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue")
abline(0, 1, lty = 2, col = "red")  # Adding a diagonal line for reference
ibrary(caret)
library(caret)
library(pROC)
# Assuming pca_df and pca_groups are your full datasets
# Split the data into training and test sets (70% train, 30% test)
set.seed(123)  # For reproducibility
index <- createDataPartition(pca_groups$Diagnosis, p = 0.7, list = FALSE)
train_pca_df <- pca_df[index, ]
test_pca_df <- pca_df[-index, ]
train_pca_groups <- pca_groups[index, ]
test_pca_groups <- pca_groups[-index, ]
# Perform PCA on the training set
pca_model <- prcomp(train_pca_df, center = TRUE, scale. = TRUE)
# Transform the training and test sets
train_pca <- predict(pca_model, train_pca_df)
test_pca <- predict(pca_model, test_pca_df)
# Combine the PCA components with the diagnosis for the training set
train_data <- data.frame(Diagnosis = train_pca_groups$Diagnosis, train_pca)
library(caret)
library(pROC)
# Assuming pca_df and pca_groups are your full datasets
# Split the data into training and test sets (70% train, 30% test)
set.seed(123)  # For reproducibility
index <- createDataPartition(pca_groups$Diagnosis, p = 0.7, list = FALSE)
train_pca_df <- pca_df[index, ]
test_pca_df <- pca_df[-index, ]
train_pca_groups <- pca_groups[index, , drop = FALSE]
test_pca_groups <- pca_groups[-index, , drop = FALSE]
# Perform PCA on the training set
pca_model <- prcomp(train_pca_df, center = TRUE, scale. = TRUE)
# Transform the training and test sets
train_pca <- predict(pca_model, train_pca_df)
test_pca <- predict(pca_model, test_pca_df)
# Combine the PCA components with the diagnosis for the training set
train_data <- data.frame(Diagnosis = train_pca_groups$Diagnosis, train_pca)
# Train logistic regression model on the training data
lg_model <- glm(Diagnosis ~ ., data = train_data, family = binomial())
# Transform test_pca data to match the model's expectations (as a dataframe)
test_data <- data.frame(test_pca)
# Predict probabilities on the test set
probabilities <- predict(lg_model, newdata = test_data, type = "response")
# You can create a prediction object using pROC package, make sure to pass the appropriate labels from test_pca_groups
roc_data <- roc(response = test_pca_groups$Diagnosis, predictor = probabilities)
# Plot ROC curve
plot(roc_data, main = "ROC Curve")
abline(0, 1, lty = 2, col = "red")
library(caret)
library(pROC)
# Assuming pca_df and pca_groups are your full datasets
# Split the data into training and test sets (70% train, 30% test)
set.seed(123)  # For reproducibility
index <- createDataPartition(pca_groups$Diagnosis, p = 0.7, list = FALSE)
train_pca_df <- pca_df[index, ]
test_pca_df <- pca_df[-index, ]
train_pca_groups <- pca_groups[index, , drop = FALSE]
test_pca_groups <- pca_groups[-index, , drop = FALSE]
# Perform PCA on the training set
pca_model <- prcomp(train_pca_df, center = TRUE, scale. = TRUE)
# Transform the training and test sets
train_pca <- predict(pca_model, train_pca_df)
test_pca <- predict(pca_model, test_pca_df)
# Combine the PCA components with the diagnosis for the training set
train_data <- data.frame(Diagnosis = train_pca_groups$Diagnosis, train_pca)
# Train logistic regression model on the training data
lg_model <- glm(Diagnosis ~ ., data = train_data, family = binomial())
# Transform test_pca data to match the model's expectations (as a dataframe)
test_data <- data.frame(test_pca)
# Predict probabilities on the training set for ROC
train_probabilities <- predict(lg_model, newdata = train_data, type = "response")
# Predict probabilities on the test set for ROC
test_probabilities <- predict(lg_model, newdata = test_data, type = "response")
# Create a ROC curve object for the training set
roc_train <- roc(response = train_pca_groups$Diagnosis, predictor = train_probabilities)
# Create a ROC curve object for the test set
roc_test <- roc(response = test_pca_groups$Diagnosis, predictor = test_probabilities)
# Plot ROC curve for both
plot(roc_train, main = "ROC Curve", col = "blue")
lines(roc_test$specificities, roc_test$sensitivities, col = "red")
legend("bottomright", legend=c("Train", "Test"), col=c("blue", "red"), lwd=2)
abline(0, 1, lty = 2, col = "gray")
library(caret)
library(pROC)
# Assuming pca_df and pca_groups are your full datasets
# Split the data into training and test sets (70% train, 30% test)
set.seed(123)  # For reproducibility
index <- createDataPartition(pca_groups$Diagnosis, p = 0.7, list = FALSE)
train_pca_df <- pca_df[index, ]
test_pca_df <- pca_df[-index, ]
train_pca_groups <- pca_groups[index, , drop = FALSE]
test_pca_groups <- pca_groups[-index, , drop = FALSE]
# Perform PCA on the training set
pca_model <- prcomp(train_pca_df, center = TRUE, scale. = TRUE)
# Transform the training and test sets
train_pca <- predict(pca_model, train_pca_df)
test_pca <- predict(pca_model, test_pca_df)
# Combine the PCA components with the diagnosis for the training set
train_data <- data.frame(Diagnosis = train_pca_groups$Diagnosis, train_pca)
# Train logistic regression model on the training data
lg_model <- glm(Diagnosis ~ ., data = train_data, family = binomial())
# Transform test_pca data to match the model's expectations (as a dataframe)
test_data <- data.frame(test_pca)
# Predict probabilities on the training set for ROC
train_probabilities <- predict(lg_model, newdata = train_data, type = "response")
# Predict probabilities on the test set for ROC
test_probabilities <- predict(lg_model, newdata = test_data, type = "response")
# Create a ROC curve object for the training set
roc_train <- roc(response = train_pca_groups$Diagnosis, predictor = train_probabilities)
# Create a ROC curve object for the test set
roc_test <- roc(response = test_pca_groups$Diagnosis, predictor = test_probabilities)
# Plot ROC curve for both
plot(roc_train, main = "ROC Curve for Training and Test Sets", col = "blue", print.auc=TRUE)
plot(roc_test, add=TRUE, col = "red", print.auc=TRUE)
legend("bottomright", legend=c("Train", "Test"), col=c("blue", "red"), lwd=2)
abline(a=0, b=1, lty=2, col = "black")
library(caret)
library(pROC)
# Assuming pca_df and pca_groups are your full datasets
# Split the data into training and test sets (70% train, 30% test)
set.seed(123)  # For reproducibility
index <- createDataPartition(pca_groups$Diagnosis, p = 0.7, list = FALSE)
train_pca_df <- pca_df[index, ]
test_pca_df <- pca_df[-index, ]
train_pca_groups <- pca_groups[index, , drop = FALSE]
test_pca_groups <- pca_groups[-index, , drop = FALSE]
# convert to factor
train_pca_groups$Diagnosis <- as.factor(train_pca_groups$Diagnosis)
test_pca_groups$Diagnosis <- as.factor(test_pca_groups$Diagnosis)
# Perform PCA on the training set
pca_model <- prcomp(train_pca_df, center = TRUE, scale. = TRUE)
# Transform the training and test sets
train_pca <- predict(pca_model, train_pca_df)
test_pca <- predict(pca_model, test_pca_df)
# Combine the PCA components with the diagnosis for the training set
train_data <- data.frame(Diagnosis = train_pca_groups$Diagnosis, train_pca)
# Train logistic regression model on the training data
lg_model <- glm(Diagnosis ~ ., data = train_data, family = binomial())
# Transform test_pca data to match the model's expectations (as a dataframe)
test_data <- data.frame(test_pca)
# Predict probabilities on the training set for ROC
train_probabilities <- predict(lg_model, newdata = train_data, type = "response")
# Predict probabilities on the test set for ROC
test_probabilities <- predict(lg_model, newdata = test_data, type = "response")
# Create a ROC curve object for the training set
roc_train <- roc(response = train_pca_groups$Diagnosis, predictor = train_probabilities)
# Create a ROC curve object for the test set
roc_test <- roc(response = test_pca_groups$Diagnosis, predictor = test_probabilities)
# Plot ROC curve for both
plot(roc_train, main = "ROC Curve for Training and Test Sets", col = "blue", print.auc=TRUE)
plot(roc_test, add=TRUE, col = "red", print.auc=TRUE)
legend("bottomright", legend=c("Train", "Test"), col=c("blue", "red"), lwd=2)
abline(a=0, b=1, lty=2, col = "black")
# Perform logistic regression using the principal components
lg_model <- glm(Diagnosis ~ ., data = oversampled_pc_scores, family = "binomial")
lg_reduced <- glm(Diagnosis ~ PC1, data = oversampled_pc_scores, family = "binomial")
# compare reduced with full model
anova(lg_reduced, lg_model, test = "LRT")
# the p-value is > 0.05.
# Therefore, we fail to reject the null hypothesis, suggesting that using 1 PCA component is a better model than using all PCA components.
# Check the summary of the model
summary(lg_reduced)
# OR for PC1
exp(coef(lg_reduced)["PC1"])
# The p-value is <0.05 so we conclude that PC1 gene expression is significantly associated with the presence of tumor.
# the odds of developing a tumor from PC1 gene expression is 2.3 times that of non-expression.
par(mfrow = c(2, 2))
plot(lg_reduced)
View(pca_df)
setwd("~/GitHub/Prob-and-Stats-for-Biomed/Exams/Exam II")
knitr::opts_chunk$set(echo = TRUE)
##Read Dataset
br_cancer = read.csv("Breast_Cancer.csv")
# create variable subset
pca_df = br_cancer[,c(3:32)]
# perform pca
pca_result <- prcomp(pca_df, center = TRUE, scale. = TRUE)
# Examine the summary of PCA result
summary(pca_result)
# correlation matrix
cor_matrix = cor(pca_df)
#corrplot::corrplot(cor_matrix, method="number",type="upper",tl.cex	=0.6,cl.cex=0.5,number.cex=0.5)
### Identify collinear variables (rule of thumb is pearson's correlation above 0.9 is collinear)
threshold <- 0.9
collinear_variables <- data.frame(Variable1 = character(),
Variable2 = character(),
Correlation = numeric(),
stringsAsFactors = FALSE)
# Loop through each pair of variables in the correlation matrix
for (i in 1:(ncol(cor_matrix) - 1)) {
for (j in (i + 1):ncol(cor_matrix)) {
cor_value <- cor_matrix[i, j]  # Capture the correlation value
if (abs(cor_value) > threshold) {
# Append the new row to the dataframe
collinear_variables <- rbind(collinear_variables,
data.frame(Variable1 = colnames(pca_df)[i],
Variable2 = colnames(pca_df)[j],
Correlation = cor_value))
}
}
}
# remove first variable in collinear varibles
pca2_df <- pca_df
for (i in seq_len(nrow(collinear_variables))) {
variable_to_remove <- collinear_variables$Variable1[i]
pca2_df <- pca2_df[, !(colnames(pca2_df) == variable_to_remove)]
}
# perform pca
pca2_result <- prcomp(pca2_df, center = TRUE, scale. = TRUE)
# Examine the summary of PCA result
summary(pca2_result)
library(ggplot2)
# calculate cumulative variance
variance <- pca2_result$sdev^2 / sum(pca2_result$sdev^2)
cumulative_variance <- cumsum(variance)
# Creating the scree plot
ggplot(data = data.frame(PC = 1:length(variance), Variance = variance), aes(x = PC, y = Variance)) +
geom_line(size = 1, col = "red4") +
geom_point(size = 2) +
geom_text(aes(label = round(Variance, 3)), vjust = -0.1, hjust = -0.5, colour = "black") +
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot Breast Cancer Diagnosis PCA") +
scale_x_continuous(breaks = 1:length(variance)) +
ylim(0, max(cumulative_variance) * 1.1)
# Get loadings
loadings <- pca2_result$rotation
# Analyze the first five principal components
for (pc in 1:5) {
pca_loadings <- loadings[, pc]
# Sort the eigenvectors by absolute value in descending order and take the top 3
top_contributors <- sort(abs(pca_loadings), decreasing = TRUE)[1:3]
# Get top contributing variables
top_contributor_names <- names(top_contributors)
# Print the results
cat(sprintf("Top 3 contributors for PC%d:\n", pc))
for (contributor in top_contributor_names) {
cat(sprintf("%s: %f\n", contributor, pca_loadings[contributor]))
}
cat("\n")
}
# PCA scores for five principal components
pca_subset <- pca2_result$x[, 1:5]
# set diagnosis column
diagnosis <- br_cancer$diagnosis
# Combine scores with diagnosis into one dataframe
plot_data <- data.frame(pca_subset, diagnosis = diagnosis)
library("GGally")
# PCA1 vs PCA2
fviz_pca_ind(pca2_result,
geom.ind = "point",
col.ind = factor(plot_data$diagnosis, levels = unique(plot_data$diagnosis)),
palette = c("firebrick3", "steelblue2"),
addEllipses = TRUE,
legend.title = "Groups",
title = "PC1 vs PC2",
col.lab = c("B" = "steelblue2", "M" = "firebrick3"))
install.packages("FactoMineR")
install.packages("factoextra")
# PCA scores for five principal components
pca_subset <- pca2_result$x[, 1:5]
# set diagnosis column
diagnosis <- br_cancer$diagnosis
# Combine scores with diagnosis into one dataframe
plot_data <- data.frame(pca_subset, diagnosis = diagnosis)
library("GGally")
library("factoextra")
# PCA1 vs PCA2
fviz_pca_ind(pca2_result,
geom.ind = "point",
col.ind = factor(plot_data$diagnosis, levels = unique(plot_data$diagnosis)),
palette = c("firebrick3", "steelblue2"),
addEllipses = TRUE,
legend.title = "Groups",
title = "PC1 vs PC2",
col.lab = c("B" = "steelblue2", "M" = "firebrick3"))
# PC2 vs PC3
fviz_pca_ind(pca2_result,
axes = c(2, 3),               # PC2 vs PC3
geom.ind = "point",           # Show points only
col.ind = factor(plot_data$diagnosis, levels = unique(plot_data$diagnosis)),  # Color by groups
palette = c("firebrick3", "steelblue2"),
addEllipses = TRUE,          # Concentration ellipses
legend.title = "Groups",
title = "PC2 vs PC3",
col.lab = c("B" = "steelblue2", "M" = "firebrick3"))
